arguments: src/align_dataset_mtcnn.py Dataset/FaceData/raw Dataset/FaceData/processed --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25
--------------------
tensorflow version: 1.15.5
--------------------
git hash: b'049dd45eb5707299d01f9c1b34b06c0363bf3a18'
--------------------
b'diff --git a/Models/20180402-114759.pb b/Models/20180402-114759.pb\nindex e69de29..39b4ed7 100644\nBinary files a/Models/20180402-114759.pb and b/Models/20180402-114759.pb differ\ndiff --git a/Models/facemodel.pkl b/Models/facemodel.pkl\nindex 5dd654e..fe38bc1 100644\nBinary files a/Models/facemodel.pkl and b/Models/facemodel.pkl differ\ndiff --git a/Models/model-20180402-114759.ckpt-275.data-00000-of-00001 b/Models/model-20180402-114759.ckpt-275.data-00000-of-00001\nindex e69de29..6160198 100644\nBinary files a/Models/model-20180402-114759.ckpt-275.data-00000-of-00001 and b/Models/model-20180402-114759.ckpt-275.data-00000-of-00001 differ\ndiff --git a/face_rec_flask.py b/face_rec_flask.py\nindex f50def0..ea26497 100644\n--- a/face_rec_flask.py\n+++ b/face_rec_flask.py\n@@ -55,10 +55,10 @@ ALLOWED_EXTENSIONS = set([\'txt\', \'pdf\', \'png\', \'jpg\', \'jpeg\', \'gif\'])\n UPLOAD_FOLDER_RAW = os.path.expanduser("Dataset/FaceData/raw")\n \n # Get input and output tensors\n-#images_placeholder = tf.get_default_graph().get_tensor_by_name(\'input:0\')\n-#embeddings = tf.get_default_graph().get_tensor_by_name("embeddings:0")\n-#phase_train_placeholder = tf.get_default_graph().get_tensor_by_name("phase_train:0")\n-#embedding_size = embeddings.get_shape()[1]\n+images_placeholder = tf.get_default_graph().get_tensor_by_name(\'input:0\')\n+embeddings = tf.get_default_graph().get_tensor_by_name("embeddings:0")\n+phase_train_placeholder = tf.get_default_graph().get_tensor_by_name("phase_train:0")\n+embedding_size = embeddings.get_shape()[1]\n pnet, rnet, onet = src.align.detect_face.create_mtcnn(sess, "src/align")\n \n app = Flask(__name__)\n@@ -76,22 +76,193 @@ CORS(app)\n def index():\n     return "OK!";\n \n+@app.route(\'/identified\', methods=[\'POST\'])\n+@cross_origin()\n+def upload_img_file():\n+    if request.method == \'POST\':\n+        # base 64\n+        name="Unknown"\n+\n+        f = request.files.get(\'image\')\n+\n+        image = np.asarray(bytearray(f.read()), dtype="uint8")\n+\n+        frame = cv2.imdecode(image, cv2.IMREAD_COLOR)\n+\n+        bounding_boxes, _ = src.align.detect_face.detect_face(frame, MINSIZE, pnet, rnet, onet, THRESHOLD, FACTOR)\n+\n+        faces_found = bounding_boxes.shape[0]\n+        try:\n+            # Neu co it nhat 1 khuon mat trong frame\n+            if faces_found > 0:\n+                det = bounding_boxes[:, 0:4]\n+                bb = np.zeros((faces_found, 4), dtype=np.int32)\n+                for i in range(faces_found):\n+                    bb[i][0] = det[i][0]\n+                    bb[i][1] = det[i][1]\n+                    bb[i][2] = det[i][2]\n+                    bb[i][3] = det[i][3]\n+\n+                    # Cat phan khuon mat tim duoc\n+                    cropped = frame[bb[i][1]:bb[i][3], bb[i][0]:bb[i][2], :]\n+                    scaled = cv2.resize(cropped, (INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE),\n+                                        interpolation=cv2.INTER_CUBIC)\n+                    scaled = src.facenet.prewhiten(scaled)\n+                    scaled_reshape = scaled.reshape(-1, INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE, 3)\n+                    feed_dict = {images_placeholder: scaled_reshape, phase_train_placeholder: False}\n+                    emb_array = sess.run(embeddings, feed_dict=feed_dict)\n+\n+                    # Dua vao model de classifier\n+                    predictions = model.predict_proba(emb_array)\n+                    best_class_indices = np.argmax(predictions, axis=1)\n+                    best_class_probabilities = predictions[\n+                        np.arange(len(best_class_indices)), best_class_indices]\n+\n+                    # Lay ra ten va ty le % cua class co ty le cao nhat\n+                    best_name = class_names[best_class_indices[0]]\n+                    print("Name: {}, Probability: {}".format(best_name, best_class_probabilities))\n+\n+                    # Neu ty le nhan dang > 0.5 thi hien thi ten\n+                    if best_class_probabilities > 0.7:\n+                        name = class_names[best_class_indices[0]]\n+                    else:\n+                        # Con neu <=0.5 thi hien thi Unknow\n+                        name = "Unknown"\n+        except:\n+            pass\n+    return name;\n+\n+@app.route(\'/identifiedStr\', methods=[\'POST\'])\n+@cross_origin()\n+def upload_img_file_str():\n+    if request.method == \'POST\':\n+        # base 64\n+        name="NULL"\n+\n+        url_img = request.json[\'url\']\n+\n+        f = requests.get(url_img, stream=True)\n+\n+        image = np.asarray(bytearray(f.content), dtype="uint8")\n+\n+        frame = cv2.imdecode(image, cv2.IMREAD_COLOR)\n+\n+        bounding_boxes, _ = src.align.detect_face.detect_face(frame, MINSIZE, pnet, rnet, onet, THRESHOLD, FACTOR)\n+\n+        faces_found = bounding_boxes.shape[0]\n+\n+        try:\n+            # Neu co it nhat 1 khuon mat trong frame\n+            if faces_found > 0:\n+                det = bounding_boxes[:, 0:4]\n+                bb = np.zeros((faces_found, 4), dtype=np.int32)\n+                for i in range(faces_found):\n+                    bb[i][0] = det[i][0]\n+                    bb[i][1] = det[i][1]\n+                    bb[i][2] = det[i][2]\n+                    bb[i][3] = det[i][3]\n+\n+                    # Cat phan khuon mat tim duoc\n+                    cropped = frame[bb[i][1]:bb[i][3], bb[i][0]:bb[i][2], :]\n+                    scaled = cv2.resize(cropped, (INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE),\n+                                        interpolation=cv2.INTER_CUBIC)\n+                    scaled = src.facenet.prewhiten(scaled)\n+                    scaled_reshape = scaled.reshape(-1, INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE, 3)\n+                    feed_dict = {images_placeholder: scaled_reshape, phase_train_placeholder: False}\n+                    emb_array = sess.run(embeddings, feed_dict=feed_dict)\n+\n+                    # Dua vao model de classifier\n+                    predictions = model.predict_proba(emb_array)\n+                    best_class_indices = np.argmax(predictions, axis=1)\n+                    best_class_probabilities = predictions[\n+                        np.arange(len(best_class_indices)), best_class_indices]\n+\n+                    # Lay ra ten va ty le % cua class co ty le cao nhat\n+                    best_name = class_names[best_class_indices[0]]\n+                    print("Name: {}, Probability: {}".format(best_name, best_class_probabilities))\n+\n+                    # Neu ty le nhan dang > 0.5 thi hien thi ten\n+                    if best_class_probabilities > 0.9:\n+                        name = class_names[best_class_indices[0]]\n+                    else:\n+                        # Con neu <=0.5 thi hien thi Unknow\n+                        return flask.jsonify()\n+        except:\n+            pass\n+    return flask.jsonify(name_rp=name)\n+\n @app.route(\'/identifiedStrListTest\', methods=[\'POST\'])\n @cross_origin()\n def upload_img_file_str_list_test():\n-    url_img = request.form[\'url\']\n+    mypath = os.path.expanduser("Dataset/FaceData/processed")\n+    onlyfiles = [f for f in listdir(mypath) if not isfile(join(mypath, f))]\n+    list = [onlyfiles[np.random.randint(0, len(onlyfiles))],onlyfiles[np.random.randint(0, len(onlyfiles))]\n+            ,onlyfiles[np.random.randint(0, len(onlyfiles))]];\n+    return jsonify(name_list_rp=list)\n \n-    f = requests.get(url_img, stream=True)\n+@app.route(\'/identifiedStrList\', methods=[\'POST\'])\n+@cross_origin()\n+def upload_img_file_str_list():\n+    if request.method == \'POST\':\n+        # base 64\n+        name="Unknown"\n \n-    image = np.asarray(bytearray(f.content), dtype="uint8")\n+        name_list = []\n \n-    mypath = os.path.expanduser("Dataset/FaceData/processed")\n-    onlyfiles = [f for f in listdir(mypath) if not isfile(join(mypath, f))]\n-    list = [onlyfiles[np.random.randint(0, len(onlyfiles))]];\n+        url_img_list = request.json[\'url_list\']\n \n-    return jsonify(name_list_rp=list)\n+        for url_img in url_img_list:\n+\n+            f = requests.get(url_img, stream=True)\n+\n+            image = np.asarray(bytearray(f.content), dtype="uint8")\n+\n+            frame = cv2.imdecode(image, cv2.IMREAD_COLOR)\n \n-@app.route(\'/tranning\', methods=[\'GET\'])\n+            bounding_boxes, _ = src.align.detect_face.detect_face(frame, MINSIZE, pnet, rnet, onet, THRESHOLD, FACTOR)\n+\n+            faces_found = bounding_boxes.shape[0]\n+\n+            try:\n+                # Neu co it nhat 1 khuon mat trong frame\n+                if faces_found > 0:\n+                    det = bounding_boxes[:, 0:4]\n+                    bb = np.zeros((faces_found, 4), dtype=np.int32)\n+                    for i in range(faces_found):\n+                        bb[i][0] = det[i][0]\n+                        bb[i][1] = det[i][1]\n+                        bb[i][2] = det[i][2]\n+                        bb[i][3] = det[i][3]\n+\n+                        # Cat phan khuon mat tim duoc\n+                        cropped = frame[bb[i][1]:bb[i][3], bb[i][0]:bb[i][2], :]\n+                        scaled = cv2.resize(cropped, (INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE),\n+                                            interpolation=cv2.INTER_CUBIC)\n+                        scaled = src.facenet.prewhiten(scaled)\n+                        scaled_reshape = scaled.reshape(-1, INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE, 3)\n+                        feed_dict = {images_placeholder: scaled_reshape, phase_train_placeholder: False}\n+                        emb_array = sess.run(embeddings, feed_dict=feed_dict)\n+\n+                        # Dua vao model de classifier\n+                        predictions = model.predict_proba(emb_array)\n+                        best_class_indices = np.argmax(predictions, axis=1)\n+                        best_class_probabilities = predictions[\n+                            np.arange(len(best_class_indices)), best_class_indices]\n+\n+                        # Lay ra ten va ty le % cua class co ty le cao nhat\n+                        best_name = class_names[best_class_indices[0]]\n+                        print("Name: {}, Probability: {}".format(best_name, best_class_probabilities))\n+\n+                        # Neu ty le nhan dang > 0.5 thi hien thi ten\n+                        if best_class_probabilities > 0.9:\n+                            name_list.append(class_names[best_class_indices[0]])\n+                            # Con neu <=0.5 thi hien thi Unknow\n+\n+            except:\n+                pass\n+    return flask.jsonify(name_list_rp=name_list)\n+\n+@app.route(\'/trainning\', methods=[\'GET\'])\n @cross_origin()\n def align_dataset_mtcnn_again():\n     os.system("python src/classifier.py TRAIN Dataset/FaceData/processed Models/20180402-114759.pb Models/facemodel.pkl --batch_size 1000")\n@@ -112,31 +283,33 @@ def align_dataset_mtcnn_again_test():\n         200,\n     )\n \n+@app.route(\'/checkAvailable\', methods=[\'GET\'])\n+@cross_origin()\n+def check_available():\n+    return make_response(\n+        jsonify(\n+            {"message": "Success"}\n+        ),\n+        200,\n+    )\n+\n @app.route(\'/deleteByIdTest\', methods=[\'POST\'])\n @cross_origin()\n def deleteByIdTest():\n-    id = request.json[\'id\']\n-\n-    if not id:\n+    if not request.json[\'id\']:\n         return make_response(\n             jsonify(\n                 {"message": "Error"}\n             ),\n             400,\n         )\n-    parent_dir = os.path.expanduser("Dataset/FaceData/raw")\n-    path = os.path.join(parent_dir, id)\n-    shutil.rmtree(path, ignore_errors=True)\n-    parent_dir = os.path.expanduser("Dataset/FaceData/processed")\n-    path = os.path.join(parent_dir, id)\n-    shutil.rmtree(path, ignore_errors=True)\n-\n-    return make_response(\n-        jsonify(\n-            {"message": "Success"}\n-        ),\n-        200,\n-    )\n+    else:\n+        return make_response(\n+            jsonify(\n+                {"message": "Delete success ID: " + str(id)}\n+            ),\n+            200,\n+        )\n \n @app.route(\'/deleteById\', methods=[\'POST\'])\n @cross_origin()\n@@ -206,13 +379,13 @@ def align_dataset_mtcnn_url():\n         )\n     url_img_list = request.json[\'url_list\']\n \n-    #if len(url_img_list) != 20:\n-    #   return make_response(\n-    #       jsonify(\n-    #            {"message": "Need 20 images for tranning"}\n-    #        ),\n-    #        400,\n-    #    )\n+    if len(url_img_list) != 20:\n+        return make_response(\n+            jsonify(\n+                {"message": "Need 20 images for tranning"}\n+            ),\n+            400,\n+        )\n \n     UPLOAD_FOLDER = os.path.expanduser("Dataset/FaceData/raw") + \'/\' + directory\n     app.config[\'UPLOAD_FOLDER\'] = UPLOAD_FOLDER\ndiff --git a/src/align/__pycache__/detect_face.cpython-37.pyc b/src/align/__pycache__/detect_face.cpython-37.pyc\nindex b160cc0..5cbc3d0 100644\nBinary files a/src/align/__pycache__/detect_face.cpython-37.pyc and b/src/align/__pycache__/detect_face.cpython-37.pyc differ\ndiff --git a/src/align/detect_face.py b/src/align/detect_face.py\nindex 88e9052..9d9ee0a 100644\n--- a/src/align/detect_face.py\n+++ b/src/align/detect_face.py\n@@ -1,28 +1,3 @@\n-""" Tensorflow implementation of the face detection / alignment algorithm found at\n-https://github.com/kpzhang93/MTCNN_face_detection_alignment\n-"""\n-# MIT License\n-# \n-# Copyright (c) 2016 David Sandberg\n-# \n-# Permission is hereby granted, free of charge, to any person obtaining a copy\n-# of this software and associated documentation files (the "Software"), to deal\n-# in the Software without restriction, including without limitation the rights\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n-# copies of the Software, and to permit persons to whom the Software is\n-# furnished to do so, subject to the following conditions:\n-# \n-# The above copyright notice and this permission notice shall be included in all\n-# copies or substantial portions of the Software.\n-# \n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n-# SOFTWARE.\n-\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\ndiff --git a/src/classifier.py b/src/classifier.py\nindex e7189bc..9de6476 100644\n--- a/src/classifier.py\n+++ b/src/classifier.py\n@@ -1,27 +1,3 @@\n-"""An example of how to use your own dataset to train a classifier that recognizes people.\n-"""\n-# MIT License\n-# \n-# Copyright (c) 2016 David Sandberg\n-# \n-# Permission is hereby granted, free of charge, to any person obtaining a copy\n-# of this software and associated documentation files (the "Software"), to deal\n-# in the Software without restriction, including without limitation the rights\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n-# copies of the Software, and to permit persons to whom the Software is\n-# furnished to do so, subject to the following conditions:\n-# \n-# The above copyright notice and this permission notice shall be included in all\n-# copies or substantial portions of the Software.\n-# \n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n-# SOFTWARE.\n-\n from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function'